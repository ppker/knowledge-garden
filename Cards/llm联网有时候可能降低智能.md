---
date created: 2025-07-06
date modified: 2025-07-11
publish: true
---

比如 Perplexity 就显得很呆，它倾向于直接去搜答案，而不是自己推理。

[[llm使用rag或memory可能降低智能]]
明确判断自己的问题，如果不是实时性很强的，其实不联网反而能获得高质量答案。因为模型预训练使用的资料，那可是人工精挑细选的，比现在推理阶段引用网上临时搜的可能都不一定靠谱的材料，要高到不知道哪里去了。
